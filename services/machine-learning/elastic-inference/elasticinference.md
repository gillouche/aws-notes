# Amazon Elastic Inference

## General info

attach low-cost GPU powered acceleration to EC2 and SageMaker instances to reduce the cost of running deep learning inference (making predictions)

supports TensorFlow, Apache MXNet, ONNX models

there is a big difference of compute power needed between a training (heavy parallelization of compute) vs inference (single)

no code change required

GPU shared with others
